global:
  # Credentials are provided via env vars, via the replication controller.
  # https://github.com/prometheus/alertmanager/blob/0318f26/notify/impl.go#L191
  smtp_smarthost: 'email-smtp.us-east-1.amazonaws.com:25'
  smtp_from: 'noreply@weave.works'

templates:
- '/etc/alertmanager/*.tmpl'

route:
  receiver: service-alerts-warning

  # Multiple alerts coming in with the same values for these label keys will
  # be batched into a single group.
  group_by: ['alertname']

  # When a new group of alerts is created by an incoming alert, wait at least
  # 'group_wait' to send the initial notification. This way ensures that you
  # get multiple alerts for the same group that start firing shortly after
  # another are batched together on the first notification.
  group_wait: 30s

  # When the first notification was sent, wait 'group_interval' to send a
  # betch of new alerts that started firing for that group.
  group_interval: 5m

  # If an alert has successfully been sent, wait 'repeat_interval' to resend
  # them.
  repeat_interval: 3h

  # If 'continue' is false, the first sub-route that matches this alert will
  # terminate the search and the alert will be inserted at that routing node.
  # If true, the alert is inserted to sibling nodes as well if there is a
  # match. This allows to do first-match semantics (=false) in smaller scopes
  # (e.g. team-level), while avoiding accidental shadowing (=true) at alerts
  # at larger scopes (e.g. company-level)
  continue: true

  # All the above attributes are inherited by all child routes and can
  # overwritten on each.

  routes:
  - receiver: service-alerts-warning
    continue: true
  - match:
      severity: critical
    receiver: service-alerts-critical
    continue: true

# Inhibition rules allow to mute a set of alerts given that another alert is
# firing. We use this to mute any warning-level notifications if the same
# alert is already critical.
inhibit_rules:
- source_match:
    severity: 'critical'
  target_match:
    severity: 'warning'
  # Apply inhibition if the alertname is the same.
  equal: ['alertname']

receivers:
- name: 'service-alerts-warning'
  slack_configs:
  - api_url: https://hooks.slack.com/services/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
    channel: cloud
    send_resolved: true
    username: prod-alert
    text: "{{ .CommonLabels.alertname }}: {{ .CommonAnnotations.summary }}"

- name: 'service-alerts-critical'
  email_configs:
  - to: 'service-alerts+critical@weave.works'
  pagerduty_configs:
  - service_key: '5d4f6937fbe74508b272004c725009e2' # PagerDuty service integration key
