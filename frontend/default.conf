# Each $binary_remote_addr occupies 64 bytes.
# So, 64 MB should roughly allow tracking roughly 1 million clients
# (64*2^20/64 = 2^20 = 1048576), limit after which nginx will start
# returning 503s for the rate-limited locations.
limit_req_zone $binary_remote_addr zone=antibf:64m rate=1r/s;
limit_req_zone $binary_remote_addr zone=antidos:64m rate=10r/s;

server {
    listen 80;
    # FIXME: this is the DNS server in the local k8s cluster
    # we should configure this dynamically from the value at /etc/resolv.conf
    # or from: kubectl --namespace=kube-system get service kube-dns -o template --template='{{.spec.clusterIP}}'
    resolver 10.0.0.10:53;

    location = /api/users/login {
        # Apply anti-bruteforce rate-limitting to login.
        # Any additional requests coming from clients exceeding the
        # rate-limit are put into a shared queue of 5 requests (which
        # will start discarding requests with 503s when full)
        limit_req zone=antibf burst=5;
        proxy_pass http://users$request_uri;
    }

    # Apply a more relaxed anti-DoS rate-limiting to all
    # authentication-unrelated endpoints
    limit_req zone=antidos burst=10;

    location /api/users/ {
        proxy_pass http://users$request_uri;
    }

    location ~ ^/api/app/[^/]+/api/topology/[^/]+/ws {
        proxy_pass http://app-mapper$request_uri;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }

    location = /api/report {
        proxy_pass http://app-mapper$request_uri;
    }

    location =/api {
        alias /home/weave/api.json;
    }

    location /api/app/ {
        proxy_pass http://app-mapper$request_uri;
    }

    location /api/org/ {
        proxy_pass http://app-mapper$request_uri;
    }

    location / {
        proxy_pass http://ui-server$request_uri;
    }
}
